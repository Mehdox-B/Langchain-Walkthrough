{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain: Q&A over Documents and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Langchain Classes\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.indexes import  VectorstoreIndexCreator\n",
    "from langchain_openai.embeddings import  OpenAIEmbeddings\n",
    "from IPython.display import display,Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA\n",
    "* This chain first does a retrieval step to fetch relevant documents, then passes those documents into an LLM to generate a response.\n",
    "### DocArrayInMemorySearch\n",
    "* DocArrayInMemorySearch is a document index provided by Docarray that stores documents in memory. It is a great starting point for small datasets, where you may not want to launch a database server.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = \"../Data/Client.csv\"\n",
    "csv_loader = CSVLoader(file_path=csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(\n",
    "  api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "  model=\"text-embedding-3-small\"\n",
    ")\n",
    "indexed_vectoreStore = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=FAISS,\n",
    "    embedding=embedding_model\n",
    ").from_loaders([csv_loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I want to know adresses of all the client named john .\\\n",
    "      Structure the response into a table in markdown and summarize it the content of the generated table \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here is the information about clients named \"john\" structured in a table:\n",
       "\n",
       "| id_client | Nom  | Prenom | Adresse           |\n",
       "|-----------|------|--------|-------------------|\n",
       "| 61        | john | johnson| 234 Main St, New York |\n",
       "| 51        | john | Smith  | 234 Elm St, New York |\n",
       "\n",
       "Summary:\n",
       "The table lists the addresses of all clients named \"john.\" There are two clients with the first name \"john,\" one residing at 234 Main St, New York and the other at 234 Elm St, New York."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_llm_model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "response = indexed_vectoreStore.query(\n",
    "    llm=base_llm_model,\n",
    "    question=query\n",
    "    )\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step By Step Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='id_client: 41\\nNom: John\\nPrenom: Doe\\nAdresse: 123 Main St, New York\\nTelephone: 5551234567', metadata={'source': '../Data/Client.csv', 'row': 0}),\n",
       " Document(page_content='id_client: 42\\nNom: Jane\\nPrenom: Smith\\nAdresse: 456 Elm St, Los Angeles\\nTelephone: 5559876543', metadata={'source': '../Data/Client.csv', 'row': 1}),\n",
       " Document(page_content='id_client: 43\\nNom: Michael\\nPrenom: Johnson\\nAdresse: \\nTelephone: 5551112222', metadata={'source': '../Data/Client.csv', 'row': 2}),\n",
       " Document(page_content='id_client: 44\\nNom: Emily\\nPrenom: Williams\\nAdresse: 321 Maple Ln, Houston\\nTelephone: ', metadata={'source': '../Data/Client.csv', 'row': 3}),\n",
       " Document(page_content='id_client: 45\\nNom: Christopher\\nPrenom: \\nAdresse: 654 Cedar Rd, Phoenix\\nTelephone: 5555556666', metadata={'source': '../Data/Client.csv', 'row': 4})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "csv_loader = CSVLoader(file_path=\"../Data/Client.csv\")\n",
    "\n",
    "loaded_csv_document = csv_loader.load()\n",
    "## Display the first 5 document\n",
    "loaded_csv_document[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017455831170082092,\n",
       " -0.02263569086790085,\n",
       " -0.003403961891308427,\n",
       " 0.0127999447286129,\n",
       " 0.005284655373543501]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example how the embedding layer is applied\n",
    "embedding_model.embed_query(\"Hello langchain Community\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='id_client: 61\\nNom: john\\nPrenom: johnson\\nAdresse: 234 Main St, New York\\nTelephone: 5551234567', metadata={'source': '../Data/Client.csv', 'row': 20}),\n",
       " Document(page_content='id_client: 41\\nNom: John\\nPrenom: Doe\\nAdresse: 123 Main St, New York\\nTelephone: 5551234567', metadata={'source': '../Data/Client.csv', 'row': 0}),\n",
       " Document(page_content='id_client: 51\\nNom: john\\nPrenom: Smith\\nAdresse: 234 Elm St, New York\\nTelephone: 5551234567', metadata={'source': '../Data/Client.csv', 'row': 10}),\n",
       " Document(page_content='id_client: 42\\nNom: Jane\\nPrenom: Smith\\nAdresse: 456 Elm St, Los Angeles\\nTelephone: 5559876543', metadata={'source': '../Data/Client.csv', 'row': 1})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectoreStoreDatabase = FAISS.from_documents(\n",
    "    loaded_csv_document,\n",
    "    embedding_model\n",
    ")\n",
    "## Result based on similary search methodology\n",
    "fetched_info = vectoreStoreDatabase.similarity_search(\"give me the adresse of all client named john\")\n",
    "fetched_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Construct a retriever interface from the vectore store database\n",
    "retriever = vectoreStoreDatabase.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Stuff Document Methodology\n",
    "question_answer_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=base_llm_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stuffing Method\n",
    "* Stuff method is the simplest way to put the retrieved documents as context.All the data is simply injected into the prompt as context to pass to the language model.(LLM).\n",
    "* Pros : it makes a single call to the LLM . The LLM has access to the data at once .\n",
    "* Cons : LLMS have a context length , and for large documents or many documents this will not work as it will result in a prompt larger than the context length.\n",
    "* Alternative method : Map_reduce , Refine ,Map_rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehdi\\anaconda3\\envs\\langchain-tuto\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure! Here is a table containing the addresses of all clients named \"john\":\n",
       "\n",
       "| id_client | Nom  | Prenom    | Adresse         |\n",
       "|-----------|------|-----------|-----------------|\n",
       "| 61        | john | johnson   | 234 Main St, New York |\n",
       "| 51        | john | Smith     | 234 Elm St, New York  |\n",
       "\n",
       "Summary:\n",
       "The table lists the addresses of all clients named \"john\". There are two clients named \"john\": one with the last name \"johnson\" living at \"234 Main St, New York\" and another with the last name \"Smith\" living at \"234 Elm St, New York\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = question_answer_stuff.run(query)\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Although evaluating the outputs of Large Language Models (LLMs) is essential for anyone looking to ship robust LLM applications, LLM evaluation remains a challenging task for many. Whether you are :\n",
    "* Refining a model’s accuracy through fine-tuning \n",
    "* Enhancing a Retrieval-Augmented Generation (RAG) system’s contextual relevancy.\n",
    "\n",
    "Understanding how to develop and decide on the appropriate set of LLM evaluation metrics for your use case is imperative to building a bulletproof LLM evaluation pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard-coded examples for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\":\"Does any of the client named john live in the 234 Main St, New York adresse\",\n",
    "        \"answer\":\"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"query\":\"Give me the adresse of a client named john smith\",\n",
    "        \"answer\":\"234 Elm St, New York\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-Generated examples (Automating Hrad-coding Examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LLM Chain for generating examples for question answering.\n",
    "from langchain.evaluation.qa import QAGenerateChain\n",
    "\n",
    "qa_examples_from_llm = QAGenerateChain.from_llm(\n",
    "    llm=base_llm_model\n",
    "    )\n",
    "generated_qa_examples_from_llm = qa_examples_from_llm.apply_and_parse(\n",
    "    [{\"doc\":t} for t in loaded_csv_document[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'What is the full address of the client with id_client 41?',\n",
       "  'answer': '123 Main St, New York'},\n",
       " {'query': 'What is the full name and address of the client with ID 42?',\n",
       "  'answer': 'The full name is Jane Smith, and the address is 456 Elm St, Los Angeles.'},\n",
       " {'query': 'What is the ID number and telephone number of the client named Michael Johnson?',\n",
       "  'answer': 'The ID number of the client named Michael Johnson is 43, and his telephone number is 5551112222.'},\n",
       " {'query': 'What is the full address of the client with the ID 44?',\n",
       "  'answer': '321 Maple Ln, Houston'},\n",
       " {'query': 'What is the address and telephone number for the client with the id_client 45?',\n",
       "  'answer': 'The address is 654 Cedar Rd, Phoenix, and the telephone number is 5555556666.'},\n",
       " {'query': 'Does any of the client named john live in the 234 Main St, New York adresse',\n",
       "  'answer': 'Yes'},\n",
       " {'query': 'Give me the adresse of a client named john smith',\n",
       "  'answer': '234 Elm St, New York'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_generated_qa_examples_from_llm = [];\n",
    "for qa_gen in generated_qa_examples_from_llm:\n",
    "    formatted_generated_qa_examples_from_llm.append(qa_gen[\"qa_pairs\"])\n",
    "\n",
    "formatted_generated_qa_examples_from_llm += examples\n",
    "formatted_generated_qa_examples_from_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, the client named \"john\" with the last name \"johnson\" lives at 234 Main St, New York.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer_stuff.run(examples[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track/debugg steps that LLM perform to answering the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"What is the full address of the client with id_client 41?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is the full address of the client with id_client 41?\",\n",
      "  \"context\": \"id_client: 41\\nNom: John\\nPrenom: Doe\\nAdresse: 123 Main St, New York\\nTelephone: 5551234567\\n\\nid_client: 45\\nNom: Christopher\\nPrenom: \\nAdresse: 654 Cedar Rd, Phoenix\\nTelephone: 5555556666\\n\\nid_client: 43\\nNom: Michael\\nPrenom: Johnson\\nAdresse: \\nTelephone: 5551112222\\n\\nid_client: 51\\nNom: john\\nPrenom: Smith\\nAdresse: 234 Elm St, New York\\nTelephone: 5551234567\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\nid_client: 41\\nNom: John\\nPrenom: Doe\\nAdresse: 123 Main St, New York\\nTelephone: 5551234567\\n\\nid_client: 45\\nNom: Christopher\\nPrenom: \\nAdresse: 654 Cedar Rd, Phoenix\\nTelephone: 5555556666\\n\\nid_client: 43\\nNom: Michael\\nPrenom: Johnson\\nAdresse: \\nTelephone: 5551112222\\n\\nid_client: 51\\nNom: john\\nPrenom: Smith\\nAdresse: 234 Elm St, New York\\nTelephone: 5551234567\\nHuman: What is the full address of the client with id_client 41?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [1.46s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The full address of the client with id_client 41 is 123 Main St, New York.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The full address of the client with id_client 41 is 123 Main St, New York.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 20,\n",
      "                \"prompt_tokens\": 184,\n",
      "                \"total_tokens\": 204\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o\",\n",
      "              \"system_fingerprint\": \"fp_319be4768e\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-532cc628-66c1-4903-9329-3ccab26e14e6-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 184,\n",
      "              \"output_tokens\": 20,\n",
      "              \"total_tokens\": 204\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 20,\n",
      "      \"prompt_tokens\": 184,\n",
      "      \"total_tokens\": 204\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o\",\n",
      "    \"system_fingerprint\": \"fp_319be4768e\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [1.49s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The full address of the client with id_client 41 is 123 Main St, New York.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [1.51s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"The full address of the client with id_client 41 is 123 Main St, New York.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [2.68s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"The full address of the client with id_client 41 is 123 Main St, New York.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The full address of the client with id_client 41 is 123 Main St, New York.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug = True\n",
    "question_answer_stuff.run(formatted_generated_qa_examples_from_llm[0][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate all the question/answer in one shot using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehdi\\anaconda3\\envs\\langchain-tuto\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.apply` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use batch instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "langchain.debug = False\n",
    "from langchain.evaluation.qa import  QAEvalChain\n",
    "predictions = question_answer_stuff.apply(formatted_generated_qa_examples_from_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query_Answer Example : 0\n",
      "Question : What is the full address of the client with id_client 41?\n",
      "Real answer of the current question : 123 Main St, New York\n",
      "Predicted Answer from the LLM chain : The full address of the client with id_client 41 is 123 Main St, New York.\n",
      "Predicted Grade of the result : CORRECT\n",
      "-------------------------------------\n",
      "Query_Answer Example : 1\n",
      "Question : What is the full name and address of the client with ID 42?\n",
      "Real answer of the current question : The full name is Jane Smith, and the address is 456 Elm St, Los Angeles.\n",
      "Predicted Answer from the LLM chain : The full name of the client with ID 42 is Jane Smith, and the address is 456 Elm St, Los Angeles.\n",
      "Predicted Grade of the result : CORRECT\n",
      "-------------------------------------\n",
      "Query_Answer Example : 2\n",
      "Question : What is the ID number and telephone number of the client named Michael Johnson?\n",
      "Real answer of the current question : The ID number of the client named Michael Johnson is 43, and his telephone number is 5551112222.\n",
      "Predicted Answer from the LLM chain : The ID number of the client named Michael Johnson is 43, and the telephone number is 5551112222.\n",
      "Predicted Grade of the result : CORRECT\n",
      "-------------------------------------\n",
      "Query_Answer Example : 3\n",
      "Question : What is the full address of the client with the ID 44?\n",
      "Real answer of the current question : 321 Maple Ln, Houston\n",
      "Predicted Answer from the LLM chain : I don't know the address of the client with the ID 44. There is no information provided for a client with that ID.\n",
      "Predicted Grade of the result : INCORRECT\n",
      "-------------------------------------\n",
      "Query_Answer Example : 4\n",
      "Question : What is the address and telephone number for the client with the id_client 45?\n",
      "Real answer of the current question : The address is 654 Cedar Rd, Phoenix, and the telephone number is 5555556666.\n",
      "Predicted Answer from the LLM chain : The address for the client with the id_client 45 is 654 Cedar Rd, Phoenix, and the telephone number is 5555556666.\n",
      "Predicted Grade of the result : CORRECT\n",
      "-------------------------------------\n",
      "Query_Answer Example : 5\n",
      "Question : Does any of the client named john live in the 234 Main St, New York adresse\n",
      "Real answer of the current question : Yes\n",
      "Predicted Answer from the LLM chain : Yes, the client named John Johnson (id_client: 61) lives at 234 Main St, New York.\n",
      "Predicted Grade of the result : CORRECT\n",
      "-------------------------------------\n",
      "Query_Answer Example : 6\n",
      "Question : Give me the adresse of a client named john smith\n",
      "Real answer of the current question : 234 Elm St, New York\n",
      "Predicted Answer from the LLM chain : The address of the client named John Smith is 234 Elm St, New York.\n",
      "Predicted Grade of the result : CORRECT\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "eval_chains = QAEvalChain.from_llm(base_llm_model)\n",
    "graded_answers = eval_chains.evaluate(formatted_generated_qa_examples_from_llm,predictions)\n",
    "\n",
    "for index ,exp in enumerate(formatted_generated_qa_examples_from_llm):\n",
    "    print(f\"Query_Answer Example : {index}\")\n",
    "    print(f\"Question : \"+predictions[index][\"query\"])\n",
    "    print(f\"Real answer of the current question : \"+ predictions[index][\"answer\"])\n",
    "    print(f\"Predicted Answer from the LLM chain : \"+predictions[index][\"result\"])\n",
    "    print(\"Predicted Grade of the result : \"+graded_answers[index][\"results\"])\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain evaluation platform\n",
    "For more flexibility monitoring and automation langchain have a evaluation platform , called The LangChainSmith (Previously called Langchain Evaluation Platform), can be accessed here https://smith.langchain.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-tuto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
